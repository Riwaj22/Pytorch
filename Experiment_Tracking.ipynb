{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3021b333d2244782afcff152663d1065": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9838d3cf281347c99f49c0355ddb9761",
              "IPY_MODEL_9107b2a88f55405686ec2c875d08365b",
              "IPY_MODEL_8446987733d84a81a3b40d9c2394594d"
            ],
            "layout": "IPY_MODEL_6b9ffa240ac542e69bf084755ad498a9"
          }
        },
        "9838d3cf281347c99f49c0355ddb9761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f192247b16045d0bfb0d5e82be87cd3",
            "placeholder": "​",
            "style": "IPY_MODEL_f6cfbbe521f24d2980ab95a1f21bcbe0",
            "value": "100%"
          }
        },
        "9107b2a88f55405686ec2c875d08365b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13d4a8230ec04befa339267eac3ca3f1",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a053d0578ba943cbaf5d4fafb6064c4b",
            "value": 5
          }
        },
        "8446987733d84a81a3b40d9c2394594d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a731ee1fb55f4badab2e3e4abbe4b78d",
            "placeholder": "​",
            "style": "IPY_MODEL_9af60dff8dbb423d9869b774cf5f8ddb",
            "value": " 5/5 [00:15&lt;00:00,  3.15s/it]"
          }
        },
        "6b9ffa240ac542e69bf084755ad498a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f192247b16045d0bfb0d5e82be87cd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6cfbbe521f24d2980ab95a1f21bcbe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13d4a8230ec04befa339267eac3ca3f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a053d0578ba943cbaf5d4fafb6064c4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a731ee1fb55f4badab2e3e4abbe4b78d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9af60dff8dbb423d9869b774cf5f8ddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# For this notebook to run with updated APIs, we need torch 1.12+ and torchvision 0.13+\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "UIwUGU0QK2xI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "# Try to get torchinfo, install it if it doesn't work\n"
      ],
      "metadata": {
        "id": "N5ERsL7eK2ua"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "cpX1VKarK2sF",
        "outputId": "e6ac03b5-4f69-4397-8418-1e225660838d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seeds\n",
        "def set_seeds(seed: int=42):\n",
        "    \"\"\"Sets random sets for torch operations.\n",
        "\n",
        "    Args:\n",
        "        seed (int, optional): Random seed to set. Defaults to 42.\n",
        "    \"\"\"\n",
        "    # Set the seed for general torch operations\n",
        "    torch.manual_seed(seed)\n",
        "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
        "    torch.cuda.manual_seed(seed)"
      ],
      "metadata": {
        "id": "JQy4HdOoK2p9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import requests\n",
        "\n",
        "def download_data(source: str,\n",
        "                  destination: str,\n",
        "                  remove_source: bool = True) -> Path:\n",
        "    \"\"\"Downloads a zipped dataset from source and unzips to destination.\n",
        "\n",
        "    Args:\n",
        "        source (str): A link to a zipped file containing data.\n",
        "        destination (str): A target directory to unzip data to.\n",
        "        remove_source (bool): Whether to remove the source after downloading and extracting.\n",
        "\n",
        "    Returns:\n",
        "        pathlib.Path to downloaded data.\n",
        "\n",
        "    Example usage:\n",
        "        download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
        "                      destination=\"pizza_steak_sushi\")\n",
        "    \"\"\"\n",
        "    # Setup path to data folder\n",
        "    data_path = Path(\"data/\")\n",
        "    image_path = data_path / destination\n",
        "\n",
        "    # If the image folder doesn't exist, download it and prepare it...\n",
        "    if image_path.is_dir():\n",
        "        print(f\"[INFO] {image_path} directory exists, skipping download.\")\n",
        "    else:\n",
        "        print(f\"[INFO] Did not find {image_path} directory, creating one...\")\n",
        "        image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Download pizza, steak, sushi data\n",
        "        target_file = Path(source).name\n",
        "        with open(data_path / target_file, \"wb\") as f:\n",
        "            request = requests.get(source)\n",
        "            print(f\"[INFO] Downloading {target_file} from {source}...\")\n",
        "            f.write(request.content)\n",
        "\n",
        "        # Unzip pizza, steak, sushi data\n",
        "        with zipfile.ZipFile(data_path / target_file, \"r\") as zip_ref:\n",
        "            print(f\"[INFO] Unzipping {target_file} data...\")\n",
        "            zip_ref.extractall(image_path)\n",
        "\n",
        "        # Remove .zip file\n",
        "        if remove_source:\n",
        "            os.remove(data_path / target_file)\n",
        "\n",
        "    return image_path\n",
        "\n",
        "image_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
        "                           destination=\"pizza_steak_sushi\")\n",
        "image_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzY1r0TfK2ny",
        "outputId": "e2761c3a-6474-4238-fb07-6b53a2f4ce39"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Did not find data/pizza_steak_sushi directory, creating one...\n",
            "[INFO] Downloading pizza_steak_sushi.zip from https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip...\n",
            "[INFO] Unzipping pizza_steak_sushi.zip data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('data/pizza_steak_sushi')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "\n",
        "def download_files_from_github(repository_url, folder_path, file_extension='.py'):\n",
        "    response = requests.get(f\"{repository_url}/contents/{folder_path}\")\n",
        "    files = response.json()\n",
        "\n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path)\n",
        "\n",
        "    for file in files:\n",
        "        if file['type'] == 'file' and file['name'].endswith(file_extension):\n",
        "            file_url = file['download_url']\n",
        "            file_content = requests.get(file_url).text\n",
        "\n",
        "            file_path = os.path.join(folder_path, file['name'])\n",
        "            with open(file_path, 'w') as f:\n",
        "                f.write(file_content)\n",
        "\n",
        "            print(f\"Downloaded: {file_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    repository_url = \"https://api.github.com/repos/Riwaj22/Pytorch\"\n",
        "    folder_path = \"Going Modular\"\n",
        "    file_extension = \".py\"\n",
        "\n",
        "    download_files_from_github(repository_url, folder_path, file_extension)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRlFhLeDNX2O",
        "outputId": "e3fb5520-af69-47d7-fa8f-e410aa5159d9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded: Going Modular/data_setup.py\n",
            "Downloaded: Going Modular/evaluation_utils.py\n",
            "Downloaded: Going Modular/github_downloader.py\n",
            "Downloaded: Going Modular/plotting_curves.py\n",
            "Downloaded: Going Modular/prediction_on_uploaded_image.py\n",
            "Downloaded: Going Modular/training_utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/Going Modular')\n",
        "\n",
        "import evaluation_utils, plotting_curves, prediction_on_uploaded_image, training_utils, data_setup\n",
        "from data_setup import *\n",
        "from evaluation_utils import *\n",
        "from plotting_curves import *\n",
        "from prediction_on_uploaded_image import *\n",
        "from training_utils import *\n"
      ],
      "metadata": {
        "id": "CtSI71_qNZZi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup directories\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\"\n",
        "\n",
        "# Setup ImageNet normalization levels (turns all images into similar distribution as ImageNet)\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "# Create transform pipeline manually\n",
        "manual_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "print(f\"Manually created transforms: {manual_transforms}\")\n",
        "\n",
        "# Create data loaders\n",
        "train_dataloader, test_dataloader, class_names = create_dataloaders(\n",
        "    train_dir=train_dir,\n",
        "    test_dir=test_dir,\n",
        "    transform=manual_transforms, # use manually created transforms\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlmYyxy3K2lp",
        "outputId": "6d5d98da-7c37-4395-b6f5-357943247628"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manually created transforms: Compose(\n",
            "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7a43b3f987c0>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7a43b3f98820>,\n",
              " ['pizza', 'steak', 'sushi'])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup dirs\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\"\n",
        "\n",
        "# Setup pretrained weights (plenty of these available in torchvision.models)\n",
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
        "\n",
        "# Get transforms from weights (these are the transforms that were used to obtain the weights)\n",
        "automatic_transforms = weights.transforms()\n",
        "print(f\"Automatically created transforms: {automatic_transforms}\")\n",
        "\n",
        "# Create data loaders\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
        "    train_dir=train_dir,\n",
        "    test_dir=test_dir,\n",
        "    transform=automatic_transforms, # use automatic created transforms\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyNDCbEtK2jX",
        "outputId": "c0efda8a-2d29-4562-acdb-9c2f55901bfd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatically created transforms: ImageClassification(\n",
            "    crop_size=[224]\n",
            "    resize_size=[256]\n",
            "    mean=[0.485, 0.456, 0.406]\n",
            "    std=[0.229, 0.224, 0.225]\n",
            "    interpolation=InterpolationMode.BICUBIC\n",
            ")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7a43b3f9a5f0>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7a43b3f98100>,\n",
              " ['pizza', 'steak', 'sushi'])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: This is how a pretrained model would be created in torchvision > 0.13, it will be deprecated in future versions.\n",
        "# model = torchvision.models.efficientnet_b0(pretrained=True).to(device) # OLD\n",
        "\n",
        "# Download the pretrained weights for EfficientNet_B0\n",
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # NEW in torchvision 0.13, \"DEFAULT\" means \"best weights available\"\n",
        "\n",
        "# Setup the model with the pretrained weights and send it to the target device\n",
        "model = torchvision.models.efficientnet_b0(weights=weights).to(device)\n",
        "\n",
        "# View the output of the model\n",
        "# model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "76zj8bCFK2hH",
        "outputId": "9731c871-84c3-4d48-b6c0-e69e36242363"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-3dd342df.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-3dd342df.pth\n",
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 74.7MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "invalid hash value (expected \"3dd342df\", got \"7f5810bc96def8f7552d5b7e68d53c4786f81167d28291b21c0d90e1fca14934\")",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-ee81becfc0bd>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Setup the model with the pretrained weights and send it to the target device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mefficientnet_b0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# View the output of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyword_only_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py\u001b[0m in \u001b[0;36minner_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mweights_param\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_weights_arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/efficientnet.py\u001b[0m in \u001b[0;36mefficientnet_b0\u001b[0;34m(weights, progress, **kwargs)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[0minverted_residual_setting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_channel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_efficientnet_conf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"efficientnet_b0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth_mult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_mult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m     return _efficientnet(\n\u001b[0m\u001b[1;32m    771\u001b[0m         \u001b[0minverted_residual_setting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_channel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/efficientnet.py\u001b[0m in \u001b[0;36m_efficientnet\u001b[0;34m(inverted_residual_setting, dropout, last_channel, weights, progress, **kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_hash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/_api.py\u001b[0m in \u001b[0;36mget_state_dict\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_state_dict_from_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36mload_state_dict_from_url\u001b[0;34m(url, model_dir, map_location, progress, check_hash, file_name, weights_only)\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHASH_REGEX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# r is Optional[Match[str]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0mhash_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m         \u001b[0mdownload_url_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhash_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_legacy_zip_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/hub.py\u001b[0m in \u001b[0;36mdownload_url_to_file\u001b[0;34m(url, dst, hash_prefix, progress)\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0mdigest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msha256\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhexdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdigest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhash_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mhash_prefix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'invalid hash value (expected \"{hash_prefix}\", got \"{digest}\")'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: invalid hash value (expected \"3dd342df\", got \"7f5810bc96def8f7552d5b7e68d53c4786f81167d28291b21c0d90e1fca14934\")"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all base layers by setting requires_grad attribute to False\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Since we're creating a new layer with random weights (torch.nn.Linear),\n",
        "# let's set the seeds\n",
        "set_seeds()\n",
        "\n",
        "# Update the classifier head to suit our problem\n",
        "model.classifier = torch.nn.Sequential(\n",
        "    nn.Dropout(p=0.2, inplace=True),\n",
        "    nn.Linear(in_features=1280,\n",
        "              out_features=len(class_names),\n",
        "              bias=True).to(device))"
      ],
      "metadata": {
        "id": "a_8r3JrlK2fM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "ZZh1UMY4K2cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Create a writer with all default settings\n",
        "writer = SummaryWriter()"
      ],
      "metadata": {
        "id": "91KrVCqBK2aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, List\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "# Import train() function from:\n",
        "# https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/going_modular/engine.py\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          epochs: int,\n",
        "          device: torch.device) -> Dict[str, List]:\n",
        "    \"\"\"Trains and tests a PyTorch model.\n",
        "\n",
        "    Passes a target PyTorch models through train_step() and test_step()\n",
        "    functions for a number of epochs, training and testing the model\n",
        "    in the same epoch loop.\n",
        "\n",
        "    Calculates, prints and stores evaluation metrics throughout.\n",
        "\n",
        "    Args:\n",
        "      model: A PyTorch model to be trained and tested.\n",
        "      train_dataloader: A DataLoader instance for the model to be trained on.\n",
        "      test_dataloader: A DataLoader instance for the model to be tested on.\n",
        "      optimizer: A PyTorch optimizer to help minimize the loss function.\n",
        "      loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
        "      epochs: An integer indicating how many epochs to train for.\n",
        "      device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "    Returns:\n",
        "      A dictionary of training and testing loss as well as training and\n",
        "      testing accuracy metrics. Each metric has a value in a list for\n",
        "      each epoch.\n",
        "      In the form: {train_loss: [...],\n",
        "                train_acc: [...],\n",
        "                test_loss: [...],\n",
        "                test_acc: [...]}\n",
        "      For example if training for epochs=2:\n",
        "              {train_loss: [2.0616, 1.0537],\n",
        "                train_acc: [0.3945, 0.3945],\n",
        "                test_loss: [1.2641, 1.5706],\n",
        "                test_acc: [0.3400, 0.2973]}\n",
        "    \"\"\"\n",
        "    # Create empty results dictionary\n",
        "    results = {\"train_loss\": [],\n",
        "               \"train_acc\": [],\n",
        "               \"test_loss\": [],\n",
        "               \"test_acc\": []\n",
        "    }\n",
        "\n",
        "    # Loop through training and testing steps for a number of epochs\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss, train_acc = train_step(model=model,\n",
        "                                           dataloader=train_dataloader,\n",
        "                                           loss_fn=loss_fn,\n",
        "                                           optimizer=optimizer,\n",
        "                                           device=device)\n",
        "        test_loss, test_acc = test_step(model=model,\n",
        "                                        dataloader=test_dataloader,\n",
        "                                        loss_fn=loss_fn,\n",
        "                                        device=device)\n",
        "\n",
        "        # Print out what's happening\n",
        "        print(\n",
        "          f\"Epoch: {epoch+1} | \"\n",
        "          f\"train_loss: {train_loss:.4f} | \"\n",
        "          f\"train_acc: {train_acc:.4f} | \"\n",
        "          f\"test_loss: {test_loss:.4f} | \"\n",
        "          f\"test_acc: {test_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        # Update results dictionary\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"test_loss\"].append(test_loss)\n",
        "        results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "        ### New: Experiment tracking ###\n",
        "        # Add loss results to SummaryWriter\n",
        "        writer.add_scalars(main_tag=\"Loss\",\n",
        "                           tag_scalar_dict={\"train_loss\": train_loss,\n",
        "                                            \"test_loss\": test_loss},\n",
        "                           global_step=epoch)\n",
        "\n",
        "        # Add accuracy results to SummaryWriter\n",
        "        writer.add_scalars(main_tag=\"Accuracy\",\n",
        "                           tag_scalar_dict={\"train_acc\": train_acc,\n",
        "                                            \"test_acc\": test_acc},\n",
        "                           global_step=epoch)\n",
        "\n",
        "        # Track the PyTorch model architecture\n",
        "        writer.add_graph(model=model,\n",
        "                         # Pass in an example input\n",
        "                         input_to_model=torch.randn(32, 3, 224, 224).to(device))\n",
        "\n",
        "    # Close the writer\n",
        "    writer.close()\n",
        "\n",
        "    ### End new ###\n",
        "\n",
        "    # Return the filled results at the end of the epochs\n",
        "    return results"
      ],
      "metadata": {
        "id": "jPEbzWWiLzd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_writer(experiment_name: str,\n",
        "                  model_name: str,\n",
        "                  extra: str=None) -> torch.utils.tensorboard.writer.SummaryWriter():\n",
        "    \"\"\"Creates a torch.utils.tensorboard.writer.SummaryWriter() instance saving to a specific log_dir.\n",
        "\n",
        "    log_dir is a combination of runs/timestamp/experiment_name/model_name/extra.\n",
        "\n",
        "    Where timestamp is the current date in YYYY-MM-DD format.\n",
        "\n",
        "    Args:\n",
        "        experiment_name (str): Name of experiment.\n",
        "        model_name (str): Name of model.\n",
        "        extra (str, optional): Anything extra to add to the directory. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        torch.utils.tensorboard.writer.SummaryWriter(): Instance of a writer saving to log_dir.\n",
        "\n",
        "    Example usage:\n",
        "        # Create a writer saving to \"runs/2022-06-04/data_10_percent/effnetb2/5_epochs/\"\n",
        "        writer = create_writer(experiment_name=\"data_10_percent\",\n",
        "                               model_name=\"effnetb2\",\n",
        "                               extra=\"5_epochs\")\n",
        "        # The above is the same as:\n",
        "        writer = SummaryWriter(log_dir=\"runs/2022-06-04/data_10_percent/effnetb2/5_epochs/\")\n",
        "    \"\"\"\n",
        "    from datetime import datetime\n",
        "    import os\n",
        "\n",
        "    # Get timestamp of current date (all experiments on certain day live in same folder)\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d\") # returns current date in YYYY-MM-DD format\n",
        "\n",
        "    if extra:\n",
        "        # Create log directory path\n",
        "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name, extra)\n",
        "    else:\n",
        "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name)\n",
        "\n",
        "    print(f\"[INFO] Created SummaryWriter, saving to: {log_dir}...\")\n",
        "    return SummaryWriter(log_dir=log_dir)"
      ],
      "metadata": {
        "id": "nHU1BOYeL3j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, List\n",
        "from tqdm.auto import tqdm\n",
        "from torch.utils.tensorboard import writer\n",
        "# Add writer parameter to train()\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          epochs: int,\n",
        "          device: torch.device,\n",
        "          writer: torch.utils.tensorboard.writer.SummaryWriter # new parameter to take in a writer\n",
        "          ) -> Dict[str, List]:\n",
        "    \"\"\"Trains and tests a PyTorch model.\n",
        "\n",
        "    Passes a target PyTorch models through train_step() and test_step()\n",
        "    functions for a number of epochs, training and testing the model\n",
        "    in the same epoch loop.\n",
        "\n",
        "    Calculates, prints and stores evaluation metrics throughout.\n",
        "\n",
        "    Stores metrics to specified writer log_dir if present.\n",
        "\n",
        "    Args:\n",
        "      model: A PyTorch model to be trained and tested.\n",
        "      train_dataloader: A DataLoader instance for the model to be trained on.\n",
        "      test_dataloader: A DataLoader instance for the model to be tested on.\n",
        "      optimizer: A PyTorch optimizer to help minimize the loss function.\n",
        "      loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
        "      epochs: An integer indicating how many epochs to train for.\n",
        "      device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "      writer: A SummaryWriter() instance to log model results to.\n",
        "\n",
        "    Returns:\n",
        "      A dictionary of training and testing loss as well as training and\n",
        "      testing accuracy metrics. Each metric has a value in a list for\n",
        "      each epoch.\n",
        "      In the form: {train_loss: [...],\n",
        "                train_acc: [...],\n",
        "                test_loss: [...],\n",
        "                test_acc: [...]}\n",
        "      For example if training for epochs=2:\n",
        "              {train_loss: [2.0616, 1.0537],\n",
        "                train_acc: [0.3945, 0.3945],\n",
        "                test_loss: [1.2641, 1.5706],\n",
        "                test_acc: [0.3400, 0.2973]}\n",
        "    \"\"\"\n",
        "    # Create empty results dictionary\n",
        "    results = {\"train_loss\": [],\n",
        "               \"train_acc\": [],\n",
        "               \"test_loss\": [],\n",
        "               \"test_acc\": []\n",
        "    }\n",
        "\n",
        "    # Loop through training and testing steps for a number of epochs\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss, train_acc = train_step(model=model,\n",
        "                                          dataloader=train_dataloader,\n",
        "                                          loss_fn=loss_fn,\n",
        "                                          optimizer=optimizer,\n",
        "                                          device=device)\n",
        "        test_loss, test_acc = test_step(model=model,\n",
        "          dataloader=test_dataloader,\n",
        "          loss_fn=loss_fn,\n",
        "          device=device)\n",
        "\n",
        "        # Print out what's happening\n",
        "        print(\n",
        "          f\"Epoch: {epoch+1} | \"\n",
        "          f\"train_loss: {train_loss:.4f} | \"\n",
        "          f\"train_acc: {train_acc:.4f} | \"\n",
        "          f\"test_loss: {test_loss:.4f} | \"\n",
        "          f\"test_acc: {test_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        # Update results dictionary\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"test_loss\"].append(test_loss)\n",
        "        results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "\n",
        "        ### New: Use the writer parameter to track experiments ###\n",
        "        # See if there's a writer, if so, log to it\n",
        "        if writer:\n",
        "            # Add results to SummaryWriter\n",
        "            writer.add_scalars(main_tag=\"Loss\",\n",
        "                               tag_scalar_dict={\"train_loss\": train_loss,\n",
        "                                                \"test_loss\": test_loss},\n",
        "                               global_step=epoch)\n",
        "            writer.add_scalars(main_tag=\"Accuracy\",\n",
        "                               tag_scalar_dict={\"train_acc\": train_acc,\n",
        "                                                \"test_acc\": test_acc},\n",
        "                               global_step=epoch)\n",
        "\n",
        "            # Close the writer\n",
        "            writer.close()\n",
        "        else:\n",
        "            pass\n",
        "    ### End new ###\n",
        "\n",
        "    # Return the filled results at the end of the epochs\n",
        "    return results"
      ],
      "metadata": {
        "id": "MybEGqpfL9yR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_10_percent_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
        "                                     destination=\"pizza_steak_sushi\")\n",
        "\n",
        "data_20_percent_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\",\n",
        "                                     destination=\"pizza_steak_sushi_20_percent\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4Tw_11cMBo_",
        "outputId": "8e50e521-2906-41af-cc8b-cb1f8dc19953"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] data/pizza_steak_sushi directory exists, skipping download.\n",
            "[INFO] data/pizza_steak_sushi_20_percent directory exists, skipping download.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup training directory paths\n",
        "train_dir_10_percent = data_10_percent_path / \"train\"\n",
        "train_dir_20_percent = data_20_percent_path / \"train\"\n",
        "\n",
        "# Setup testing directory paths (note: use the same test dataset for both to compare the results)\n",
        "test_dir = data_10_percent_path / \"test\"\n",
        "\n",
        "# Check the directories\n",
        "print(f\"Training directory 10%: {train_dir_10_percent}\")\n",
        "print(f\"Training directory 20%: {train_dir_20_percent}\")\n",
        "print(f\"Testing directory: {test_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gzcStSgMEot",
        "outputId": "3c944f5f-f1d3-4d5c-e76d-cf74a301e14b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training directory 10%: data/pizza_steak_sushi/train\n",
            "Training directory 20%: data/pizza_steak_sushi_20_percent/train\n",
            "Testing directory: data/pizza_steak_sushi/test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# Create a transform to normalize data distribution to be inline with ImageNet\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], # values per colour channel [red, green, blue]\n",
        "                                 std=[0.229, 0.224, 0.225]) # values per colour channel [red, green, blue]\n",
        "\n",
        "# Compose transforms into a pipeline\n",
        "simple_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # 1. Resize the images\n",
        "    transforms.ToTensor(), # 2. Turn the images into tensors with values between 0 & 1\n",
        "    normalize # 3. Normalize the images so their distributions match the ImageNet dataset\n",
        "])"
      ],
      "metadata": {
        "id": "5xcD1yOVMGKF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "# Create 10% training and test DataLoaders\n",
        "\n",
        "# Create 20% training and test data DataLoders\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir_20_percent,\n",
        "    test_dir=test_dir,\n",
        "    transform=simple_transform,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "# Find the number of samples/batches per dataloader (using the same test_dataloader for both experiments)\n"
      ],
      "metadata": {
        "id": "Le0GThplMHo2"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torch import nn\n",
        "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights, efficientnet_b5, EfficientNet_B5_Weights\n",
        "from torchvision.models._api import WeightsEnum\n",
        "from torch.hub import load_state_dict_from_url\n",
        "\n",
        "# Get num out features (one for each class pizza, steak, sushi)\n",
        "OUT_FEATURES = len(class_names)\n",
        "\n",
        "# Create an EffNetB0 feature extractor\n",
        "def create_effnetb1():\n",
        "    # 1. Get the base mdoel with pretrained weights and send to target device\n",
        "    weights = torchvision.models.EfficientNet_B1_Weights.DEFAULT\n",
        "    model = torchvision.models.efficientnet_b1(weights=weights).to(device)\n",
        "\n",
        "    # 2. Freeze the base model layers\n",
        "    for param in model.features.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # 3. Set the seeds\n",
        "    set_seeds()\n",
        "\n",
        "    # 4. Change the classifier head\n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Dropout(p=0.2),\n",
        "        nn.Linear(in_features=1280, out_features=OUT_FEATURES)\n",
        "    ).to(device)\n",
        "\n",
        "    # 5. Give the model a name\n",
        "    model.name = \"effnetb1\"\n",
        "    print(f\"[INFO] Created new {model.name} model.\")\n",
        "    return model\n",
        "\n",
        "# Create an EffNetB2 feature extractor\n",
        "def create_effnetb7():\n",
        "\n",
        "    weights = torchvision.models.EfficientNet_B7_Weights.DEFAULT\n",
        "    model = torchvision.models.efficientnet_b7(weights=weights).to(device)\n",
        "\n",
        "    # 2. Freeze the base model layers\n",
        "    for param in model.features.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # 3. Set the seeds\n",
        "    set_seeds()\n",
        "\n",
        "    # 4. Change the classifier head\n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Dropout(p=0.2),\n",
        "        nn.Linear(in_features=2560 , out_features=OUT_FEATURES)\n",
        "    ).to(device)\n",
        "\n",
        "    # 5. Give the model a name\n",
        "    model.name = \"effnetb7\"\n",
        "    print(f\"[INFO] Created new {model.name} model.\")\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "GVAcsEZ5MJta"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of in_features to final layer of EfficientNetB2: {len(effnetb5.classifier.state_dict()['1.weight'][0])}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lofUM9eER1id",
        "outputId": "7ecdf28d-4095-4f5d-c8ee-2eb7edfe1a8e"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of in_features to final layer of EfficientNetB2: 2048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb1 = create_effnetb1()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTpbXdANMQOR",
        "outputId": "8054df80-a032-4731-a0ac-d930c2467b49"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Created new effnetb1 model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb7 = create_effnetb7()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHhXtuzhMRjo",
        "outputId": "109e695f-229c-4d78-9462-efcaef5208e4"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Created new effnetb7 model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create epochs list\n",
        "num_epochs = [5, 10, 25,50]\n",
        "\n",
        "# 2. Create models list (need to create a new model for each experiment)\n",
        "models = [\"effnetb1\", \"effnetb7\"]\n",
        "\n",
        "# 3. Create dataloaders dictionary for various dataloaders\n",
        "train_dataloaders = {\"train_data_loader\": train_dataloader\n",
        "                    }\n"
      ],
      "metadata": {
        "id": "iJHXSV5pMSq8"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from training_utils import train_step, test_step"
      ],
      "metadata": {
        "id": "SrWmcZd5UOHw"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, List\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Add writer parameter to train()\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          epochs: int,\n",
        "          device: torch.device,\n",
        "          writer: torch.utils.tensorboard.writer.SummaryWriter # new parameter to take in a writer\n",
        "          ) -> Dict[str, List]:\n",
        "    \"\"\"Trains and tests a PyTorch model.\n",
        "\n",
        "    Passes a target PyTorch models through train_step() and test_step()\n",
        "    functions for a number of epochs, training and testing the model\n",
        "    in the same epoch loop.\n",
        "\n",
        "    Calculates, prints and stores evaluation metrics throughout.\n",
        "\n",
        "    Stores metrics to specified writer log_dir if present.\n",
        "\n",
        "    Args:\n",
        "      model: A PyTorch model to be trained and tested.\n",
        "      train_dataloader: A DataLoader instance for the model to be trained on.\n",
        "      test_dataloader: A DataLoader instance for the model to be tested on.\n",
        "      optimizer: A PyTorch optimizer to help minimize the loss function.\n",
        "      loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
        "      epochs: An integer indicating how many epochs to train for.\n",
        "      device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "      writer: A SummaryWriter() instance to log model results to.\n",
        "\n",
        "    Returns:\n",
        "      A dictionary of training and testing loss as well as training and\n",
        "      testing accuracy metrics. Each metric has a value in a list for\n",
        "      each epoch.\n",
        "      In the form: {train_loss: [...],\n",
        "                train_acc: [...],\n",
        "                test_loss: [...],\n",
        "                test_acc: [...]}\n",
        "      For example if training for epochs=2:\n",
        "              {train_loss: [2.0616, 1.0537],\n",
        "                train_acc: [0.3945, 0.3945],\n",
        "                test_loss: [1.2641, 1.5706],\n",
        "                test_acc: [0.3400, 0.2973]}\n",
        "    \"\"\"\n",
        "    # Create empty results dictionary\n",
        "    results = {\"train_loss\": [],\n",
        "               \"train_acc\": [],\n",
        "               \"test_loss\": [],\n",
        "               \"test_acc\": []\n",
        "    }\n",
        "\n",
        "    # Loop through training and testing steps for a number of epochs\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss, train_acc = train_step(model=model,\n",
        "                                          dataloader=train_dataloader,\n",
        "                                          loss_fn=loss_fn,\n",
        "                                          optimizer=optimizer,\n",
        "                                          device=device)\n",
        "        test_loss, test_acc = test_step(model=model,\n",
        "          dataloader=test_dataloader,\n",
        "          loss_fn=loss_fn,\n",
        "          device=device)\n",
        "\n",
        "        # Print out what's happening\n",
        "        print(\n",
        "          f\"Epoch: {epoch+1} | \"\n",
        "          f\"train_loss: {train_loss:.4f} | \"\n",
        "          f\"train_acc: {train_acc:.4f} | \"\n",
        "          f\"test_loss: {test_loss:.4f} | \"\n",
        "          f\"test_acc: {test_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        # Update results dictionary\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"test_loss\"].append(test_loss)\n",
        "        results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "\n",
        "        ### New: Use the writer parameter to track experiments ###\n",
        "        # See if there's a writer, if so, log to it\n",
        "        if writer:\n",
        "            # Add results to SummaryWriter\n",
        "            writer.add_scalars(main_tag=\"Loss\",\n",
        "                               tag_scalar_dict={\"train_loss\": train_loss,\n",
        "                                                \"test_loss\": test_loss},\n",
        "                               global_step=epoch)\n",
        "            writer.add_scalars(main_tag=\"Accuracy\",\n",
        "                               tag_scalar_dict={\"train_acc\": train_acc,\n",
        "                                                \"test_acc\": test_acc},\n",
        "                               global_step=epoch)\n",
        "\n",
        "            # Close the writer\n",
        "            writer.close()\n",
        "        else:\n",
        "            pass\n",
        "    ### End new ###\n",
        "\n",
        "    # Return the filled results at the end of the epochs\n",
        "    return results"
      ],
      "metadata": {
        "id": "CfSQ71MOP0bl"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# 1. Set the random seeds\n",
        "set_seeds(seed=42)\n",
        "\n",
        "# 2. Keep track of experiment numbers\n",
        "experiment_number = 0\n",
        "\n",
        "# 3. Loop through each DataLoader\n",
        "for dataloader_name, train_dataloader in train_dataloaders.items():\n",
        "\n",
        "    # 4. Loop through each number of epochs\n",
        "    for epochs in tqdm( num_epochs):\n",
        "\n",
        "        # 5. Loop through each model name and create a new model based on the name\n",
        "        for model_name in models:\n",
        "\n",
        "            # 6. Create information print outs\n",
        "            experiment_number += 1\n",
        "            print(f\"[INFO] Experiment number: {experiment_number}\")\n",
        "            print(f\"[INFO] Model: {model_name}\")\n",
        "            print(f\"[INFO] DataLoader: {dataloader_name}\")\n",
        "            print(f\"[INFO] Number of epochs: {epochs}\")\n",
        "\n",
        "            # 7. Select the model\n",
        "            if model_name == \"effnetb1\":\n",
        "                model = create_effnetb1() # creates a new model each time (important because we want each experiment to start from scratch)\n",
        "            else:\n",
        "                model = create_effnetb7() # creates a new model each time (important because we want each experiment to start from scratch)\n",
        "\n",
        "            # 8. Create a new loss and optimizer for every model\n",
        "            loss_fn = nn.CrossEntropyLoss()\n",
        "            optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
        "\n",
        "            # 9. Train target model with target dataloaders and track experiments\n",
        "            train(model,\n",
        "              train_data_loader=train_dataloader,\n",
        "             test_data_loader=test_dataloader,\n",
        "              optimizer=optimizer,\n",
        "              loss_fn=loss_fn,\n",
        "              epochs=epochs,\n",
        "              device=device,\n",
        "              accuracy_fn=accuracy_fn\n",
        "              )"
      ],
      "metadata": {
        "id": "OmIhREdwMZF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Create a writer with all default settings\n",
        "writer = SummaryWriter()\n",
        "\n",
        "def create_writer(experiment_name: str,\n",
        "                  model_name: str,\n",
        "                  extra: str=None) -> torch.utils.tensorboard.writer.SummaryWriter():\n",
        "    \"\"\"Creates a torch.utils.tensorboard.writer.SummaryWriter() instance saving to a specific log_dir.\n",
        "\n",
        "    log_dir is a combination of runs/timestamp/experiment_name/model_name/extra.\n",
        "\n",
        "    Where timestamp is the current date in YYYY-MM-DD format.\n",
        "\n",
        "    Args:\n",
        "        experiment_name (str): Name of experiment.\n",
        "        model_name (str): Name of model.\n",
        "        extra (str, optional): Anything extra to add to the directory. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        torch.utils.tensorboard.writer.SummaryWriter(): Instance of a writer saving to log_dir.\n",
        "\n",
        "    Example usage:\n",
        "        # Create a writer saving to \"runs/2022-06-04/data_10_percent/effnetb2/5_epochs/\"\n",
        "        writer = create_writer(experiment_name=\"data_10_percent\",\n",
        "                               model_name=\"effnetb2\",\n",
        "                               extra=\"5_epochs\")\n",
        "        # The above is the same as:\n",
        "        writer = SummaryWriter(log_dir=\"runs/2022-06-04/data_10_percent/effnetb2/5_epochs/\")\n",
        "    \"\"\"\n",
        "    from datetime import datetime\n",
        "    import os\n",
        "\n",
        "    # Get timestamp of current date (all experiments on certain day live in same folder)\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d\") # returns current date in YYYY-MM-DD format\n",
        "\n",
        "    if extra:\n",
        "        # Create log directory path\n",
        "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name, extra)\n",
        "    else:\n",
        "        log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name)\n",
        "\n",
        "    print(f\"[INFO] Created SummaryWriter, saving to: {log_dir}...\")\n",
        "    return SummaryWriter(log_dir=log_dir)"
      ],
      "metadata": {
        "id": "ljUSKtyBMcvp"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model, data_loader, optimizer, loss_fn, accuracy_fn, device):\n",
        "    model.train()\n",
        "    total_loss, total_corrects = 0.0, 0\n",
        "\n",
        "    for inputs, targets in data_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * inputs.size(0)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        total_corrects += torch.sum(predictions == targets.data)\n",
        "\n",
        "    average_loss = total_loss / len(data_loader.dataset)\n",
        "    accuracy = total_corrects.double() / len(data_loader.dataset)\n",
        "\n",
        "    return average_loss, accuracy\n",
        "\n",
        "def test_step(model, data_loader, loss_fn, accuracy_fn, device):\n",
        "    model.eval()\n",
        "    total_loss, total_corrects = 0.0, 0\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for inputs, targets in data_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, targets)\n",
        "\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "            _, predictions = torch.max(outputs, 1)\n",
        "            total_corrects += torch.sum(predictions == targets.data)\n",
        "\n",
        "    average_loss = total_loss / len(data_loader.dataset)\n",
        "    accuracy = total_corrects.double() / len(data_loader.dataset)\n",
        "\n",
        "    return average_loss, accuracy\n",
        "\n",
        "def train(model, train_data_loader, test_data_loader, optimizer, loss_fn, accuracy_fn,\n",
        "          epochs=5, early_stop_patience=3, device='cuda'):\n",
        "\n",
        "    results = {\n",
        "        'train_loss': [],\n",
        "        'train_acc': [],\n",
        "        'test_loss': [],\n",
        "        'test_acc': []\n",
        "    }\n",
        "\n",
        "    best_test_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss, train_acc = train_step(model, train_data_loader, optimizer, loss_fn, accuracy_fn, device)\n",
        "        test_loss, test_acc = test_step(model, test_data_loader, loss_fn, accuracy_fn, device)\n",
        "\n",
        "        print(f\"Epoch:{epoch + 1} | Train Loss:{train_loss:.3f} | Train Accuracy:{train_acc:.3f} | Test Loss: {test_loss:.3f}| Test accuracy:{test_acc:.3f}\")\n",
        "\n",
        "        results['train_loss'].append(train_loss)\n",
        "        results['train_acc'].append(train_acc)\n",
        "        results['test_loss'].append(test_loss)\n",
        "        results['test_acc'].append(test_acc)\n",
        "\n",
        "        # Early stopping check\n",
        "        if test_loss < best_test_loss:\n",
        "            best_test_loss = test_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= early_stop_patience:\n",
        "            print(f\"Early stopping at epoch {epoch + 1} due to no improvement in test loss.\")\n",
        "            break\n",
        "\n",
        "    return results\n",
        "\n",
        "# # main_script.py\n",
        "\n",
        "# from training_utils import train\n",
        "\n",
        "# # Example usage\n",
        "# # Assuming you have defined your model, train_data_loader, test_data_loader, optimizer, loss_fn, accuracy_fn, and device\n",
        "\n",
        "# results = train(model_0, train_data_loader, test_data_loader, optimizer, loss_fn, accuracy_fn, epochs=100, early_stop_patience=10)\n",
        "# print(results)"
      ],
      "metadata": {
        "id": "qHR7K0JXOxYa"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "  print(\"Helper function already exists\")\n",
        "else:\n",
        "  print(\"Downloading file\")\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
        "  with open(\"helper_function.py\", \"wb\") as f:\n",
        "    f.write(request.content)\n",
        "\n",
        "from helper_function import accuracy_fn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cghaoC6OPPt0",
        "outputId": "ea57db34-e69c-4c8f-bfe9-a507fe4cce21"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Viewing TensorBoard in Jupyter and Google Colab Notebooks (uncomment to view full TensorBoard instance)\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "metadata": {
        "id": "0fy1LajpZrgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the results to TensorBoard.dev (uncomment to try it out)\n",
        "!tensorboard dev upload --logdir runs \\\n",
        "    --name \"07. PyTorch Experiment Tracking: FoodVision Mini model results\" \\\n",
        "    --description \"Comparing results of different model size, training data amount and training time.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQ2QUmZbabJq",
        "outputId": "89a0786d-e435-489c-c0d5-8dd2b97e169e"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-02-01 11:27:37.109842: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-01 11:27:37.109901: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-01 11:27:37.111027: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-01 11:27:38.105350: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "****************************************************************\n",
            "****************************************************************\n",
            "****************************************************************\n",
            "\n",
            "Uploading TensorBoard logs to https://tensorboard.dev/ is no longer\n",
            "supported.\n",
            "\n",
            "TensorBoard.dev is shutting down.\n",
            "\n",
            "Please export your experiments by Dec 31, 2023.\n",
            "\n",
            "See the FAQ at https://tensorboard.dev.\n",
            "\n",
            "****************************************************************\n",
            "****************************************************************\n",
            "****************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_effnetb1()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuqH9jotbYaz",
        "outputId": "136c4ef2-1e4b-4aa4-d443-76d46f8145dc"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Created new effnetb1 model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "evcpQjl2V2zo"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, train_dataloader, test_dataloader, optimizer, loss_fn, accuracy_fn,\n",
        "          epochs=5, early_stop_patience=3, device='cuda')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483,
          "referenced_widgets": [
            "3021b333d2244782afcff152663d1065",
            "9838d3cf281347c99f49c0355ddb9761",
            "9107b2a88f55405686ec2c875d08365b",
            "8446987733d84a81a3b40d9c2394594d",
            "6b9ffa240ac542e69bf084755ad498a9",
            "8f192247b16045d0bfb0d5e82be87cd3",
            "f6cfbbe521f24d2980ab95a1f21bcbe0",
            "13d4a8230ec04befa339267eac3ca3f1",
            "a053d0578ba943cbaf5d4fafb6064c4b",
            "a731ee1fb55f4badab2e3e4abbe4b78d",
            "9af60dff8dbb423d9869b774cf5f8ddb"
          ]
        },
        "id": "ezTLtNhrcDRB",
        "outputId": "a48bf3d6-7eaa-4daf-e800-ec639cad693e"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3021b333d2244782afcff152663d1065"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1 | Train Loss:1.019 | Train Accuracy:0.560 | Test Loss: 0.876| Test accuracy:0.893\n",
            "Epoch:2 | Train Loss:0.810 | Train Accuracy:0.847 | Test Loss: 0.724| Test accuracy:0.907\n",
            "Epoch:3 | Train Loss:0.669 | Train Accuracy:0.884 | Test Loss: 0.629| Test accuracy:0.907\n",
            "Epoch:4 | Train Loss:0.559 | Train Accuracy:0.880 | Test Loss: 0.525| Test accuracy:0.933\n",
            "Epoch:5 | Train Loss:0.533 | Train Accuracy:0.898 | Test Loss: 0.485| Test accuracy:0.933\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train_loss': [1.0192166672812568,\n",
              "  0.8095520570543078,\n",
              "  0.668994590971205,\n",
              "  0.5586990759107802,\n",
              "  0.5334541625446744],\n",
              " 'train_acc': [tensor(0.5600, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.8467, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.8844, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.8800, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.8978, device='cuda:0', dtype=torch.float64)],\n",
              " 'test_loss': [0.8763387314478557,\n",
              "  0.7244117474555969,\n",
              "  0.6288263360659282,\n",
              "  0.5245049293835958,\n",
              "  0.4849625698725383],\n",
              " 'test_acc': [tensor(0.8933, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.9067, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.9067, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.9333, device='cuda:0', dtype=torch.float64),\n",
              "  tensor(0.9333, device='cuda:0', dtype=torch.float64)]}"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def evaluate_model(model, data_loader, loss_fn, accuracy_fn, custom_labels):\n",
        "    model = model.to(\"cuda\")\n",
        "\n",
        "    loss, acc = 0, 0\n",
        "    all_true_labels, all_predicted_labels = [], []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for X, y in data_loader:\n",
        "            X = X.to(\"cuda\")\n",
        "            y = y.to(\"cuda\")\n",
        "            y_pred = model(X)\n",
        "\n",
        "            loss += loss_fn(y_pred, y).detach()\n",
        "            acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
        "\n",
        "            all_true_labels.extend(y.cpu().numpy())\n",
        "            all_predicted_labels.extend(y_pred.argmax(dim=1).cpu().numpy())\n",
        "\n",
        "        loss /= len(data_loader)\n",
        "        acc /= len(data_loader)\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        all_true_labels, all_predicted_labels, average='macro', zero_division=0\n",
        "    )\n",
        "\n",
        "    conf_matrix = confusion_matrix(all_true_labels, all_predicted_labels)\n",
        "\n",
        "    result = {\n",
        "        \"model_name\": model.__class__.__name__,\n",
        "        \"model_loss\": loss.item(),\n",
        "        \"model_acc\": acc,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "        \"confusion_matrix\": conf_matrix\n",
        "    }\n",
        "\n",
        "    plot_confusion_matrix(conf_matrix, custom_labels)\n",
        "\n",
        "    return result\n",
        "\n",
        "def plot_confusion_matrix(conf_matrix, labels):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels,\n",
        "                cbar=False, linewidths=.5, annot_kws={\"size\": 24}, square=True)\n",
        "\n",
        "    for i in range(len(labels)):\n",
        "        plt.text(i + 0.5, i + 0.5, f'{conf_matrix[i, i]}', ha='center', va='center', color='red', fontsize=24)\n",
        "\n",
        "    plt.title('Confusion Matrix ')\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "SRSNHA_NU9vZ"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(model, test_dataloader, loss_fn, accuracy_fn, class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "id": "zKB45MqDbfWg",
        "outputId": "055abafb-dcd9-4813-d45b-dbc45aa9e5f5"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_name': 'EfficientNet',\n",
              " 'model_loss': 0.504970133304596,\n",
              " 'model_acc': 92.8030303030303,\n",
              " 'precision': 0.9275533661740559,\n",
              " 'recall': 0.9368647425014148,\n",
              " 'f1': 0.931111111111111,\n",
              " 'confusion_matrix': array([[24,  1,  0],\n",
              "        [ 0, 18,  1],\n",
              "        [ 1,  2, 28]])}"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxs_LI_tbhi5",
        "outputId": "c427b57e-dfe2-44c5-9f96-331c23859f2e"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pizza', 'steak', 'sushi']"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow"
      ],
      "metadata": {
        "id": "TEj2hWCxfHIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "\n",
        "warnings.simplefilter(\"ignore\")  # Ignore warnings\n",
        "# Set the random seeds\n",
        "set_seeds(seed=42)\n",
        "# mlflow.end_run()\n",
        "experiment_number = 0\n",
        "\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "test_losses = []\n",
        "test_accuracies = []\n",
        "\n",
        "\n",
        "\n",
        "# Loop through each DataLoader\n",
        "for dataloader_name, train_dataloader in train_dataloaders.items():\n",
        "\n",
        "    # Loop through each number of epochs\n",
        "    for epochs in tqdm(num_epochs):\n",
        "\n",
        "        # Loop through each model name and create a new model based on the name\n",
        "        for model_name in models:\n",
        "\n",
        "            # Create information print outs\n",
        "            print(f\"[INFO] Model: {model_name}\")\n",
        "            print(f\"[INFO] DataLoader: {dataloader_name}\")\n",
        "            print(f\"[INFO] Number of epochs: {epochs}\")\n",
        "\n",
        "            # Select the model\n",
        "            if model_name == \"effnetb1\":\n",
        "                model = create_effnetb1()\n",
        "            else:\n",
        "                model = create_effnetb7()\n",
        "\n",
        "            # Create a new loss and optimizer for every model\n",
        "            loss_fn = nn.CrossEntropyLoss()\n",
        "            optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
        "\n",
        "            # Train the model\n",
        "            train_metrics = train(model,\n",
        "                                  train_data_loader=train_dataloader,\n",
        "                                  test_data_loader=test_dataloader,\n",
        "                                  optimizer=optimizer,\n",
        "                                  loss_fn=loss_fn,\n",
        "                                  epochs=epochs,\n",
        "                                  device=device,\n",
        "                                  accuracy_fn=accuracy_fn\n",
        "                                  )\n",
        "\n",
        "            # Append metrics for plotting\n",
        "            train_losses.append(train_metrics['train_loss'])\n",
        "            train_accuracies.append(train_metrics['train_acc'])\n",
        "            test_losses.append(train_metrics['test_loss'])\n",
        "            test_accuracies.append(train_metrics['test_acc'])\n",
        "\n",
        "# Plotting\n",
        "epochs_range = range(len(train_losses))\n",
        "\n",
        "train_losses_flat = [item for sublist in train_losses for item in sublist]\n",
        "test_losses_flat = [item for sublist in test_losses for item in sublist]\n",
        "\n",
        "# Plotting\n",
        "epochs_range = range(len(train_losses_flat))\n",
        "\n",
        "for i, model_name in enumerate(models):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(epochs_range, train_losses[i], label=f'Train Loss - {model_name}', marker='o')\n",
        "    plt.plot(epochs_range, test_losses[i], label=f'Test Loss - {model_name}', marker='o')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title(f'Train and Test Loss over Epochs - Model: {model_name}')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "K7nNx6eUckQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mlflow ui --port 5000\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcVtJIjBc1fG",
        "outputId": "ccf07e32-827b-49f3-f64a-55e6b8190cf2"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-02-01 12:39:45 +0000] [42965] [INFO] Starting gunicorn 21.2.0\n",
            "[2024-02-01 12:39:45 +0000] [42965] [INFO] Listening at: http://127.0.0.1:5000 (42965)\n",
            "[2024-02-01 12:39:45 +0000] [42965] [INFO] Using worker: sync\n",
            "[2024-02-01 12:39:45 +0000] [42966] [INFO] Booting worker with pid: 42966\n",
            "[2024-02-01 12:39:45 +0000] [42967] [INFO] Booting worker with pid: 42967\n",
            "[2024-02-01 12:39:45 +0000] [42968] [INFO] Booting worker with pid: 42968\n",
            "[2024-02-01 12:39:45 +0000] [42973] [INFO] Booting worker with pid: 42973\n",
            "[2024-02-01 12:42:09 +0000] [42965] [INFO] Handling signal: int\n",
            "\n",
            "Aborted!\n",
            "[2024-02-01 12:42:09 +0000] [42966] [INFO] Worker exiting (pid: 42966)\n",
            "[2024-02-01 12:42:09 +0000] [42968] [INFO] Worker exiting (pid: 42968)\n",
            "[2024-02-01 12:42:09 +0000] [42967] [INFO] Worker exiting (pid: 42967)\n",
            "[2024-02-01 12:42:09 +0000] [42973] [INFO] Worker exiting (pid: 42973)\n",
            "[2024-02-01 12:42:09 +0000] [42965] [INFO] Shutting down: Master\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZZS0elyWecQG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}