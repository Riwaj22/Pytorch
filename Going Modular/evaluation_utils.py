# -*- coding: utf-8 -*-
"""evaluation_utils

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18qa2jn-hqtruz0VASslrP0YwhlwPr7n7
"""

import torch
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt

# evaluation_utils.py

import torch
from sklearn.metrics import precision_recall_fscore_support, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

def evaluate_model(model, data_loader, loss_fn, accuracy_fn, custom_labels):
    model = model.to("cuda")

    loss, acc = 0, 0
    all_true_labels, all_predicted_labels = [], []

    model.eval()
    with torch.inference_mode():
        for X, y in data_loader:
            X = X.to("cuda")
            y = y.to("cuda")
            y_pred = model(X)

            loss += loss_fn(y_pred, y).detach()
            acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))

            all_true_labels.extend(y.cpu().numpy())
            all_predicted_labels.extend(y_pred.argmax(dim=1).cpu().numpy())

        loss /= len(data_loader)
        acc /= len(data_loader)

    precision, recall, f1, _ = precision_recall_fscore_support(
        all_true_labels, all_predicted_labels, average='macro', zero_division=0
    )

    conf_matrix = confusion_matrix(all_true_labels, all_predicted_labels)

    result = {
        "model_name": model.__class__.__name__,
        "model_loss": loss.item(),
        "model_acc": acc,
        "precision": precision,
        "recall": recall,
        "f1": f1,
        "confusion_matrix": conf_matrix
    }

    plot_confusion_matrix(conf_matrix, custom_labels)

    return result

def plot_confusion_matrix(conf_matrix, labels):
    plt.figure(figsize=(8, 6))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels,
                cbar=False, linewidths=.5, annot_kws={"size": 24}, square=True)

    for i in range(len(labels)):
        plt.text(i + 0.5, i + 0.5, f'{conf_matrix[i, i]}', ha='center', va='center', color='red', fontsize=24)

    plt.title('Confusion Matrix ')
    plt.xlabel('Predicted Labels')
    plt.ylabel('True Labels')
    plt.show()

